<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title> - software development</title>
    <link href="https://bspace.us/tags/software-development/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://bspace.us"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2023-08-21T00:00:00+00:00</updated>
    <id>https://bspace.us/tags/software-development/atom.xml</id>
    <entry xml:lang="en">
        <title>source of truth</title>
        <published>2023-08-21T00:00:00+00:00</published>
        <updated>2023-08-21T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/source-of-truth/" type="text/html"/>
        <id>https://bspace.us/posts/source-of-truth/</id>
        
        <content type="html">&lt;p&gt;Just read a great post from long-time &lt;a href=&quot;https:&#x2F;&#x2F;code4lib.org&#x2F;&quot; title=&quot;code4lib.org link&quot;&gt;code4libber&lt;&#x2F;a&gt; Jonathan Rochkind: &amp;quot;&lt;a href=&quot;https:&#x2F;&#x2F;bibwild.wordpress.com&#x2F;2023&#x2F;03&#x2F;21&#x2F;ocfl-and-source-of-truth-two-options&#x2F;&quot; title=&quot;source of truth link&quot;&gt;OCFL and ‘source of truth’ — two options&lt;&#x2F;a&gt;&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;To give a nutshell summary, it&#x27;s first useful to be aware of a common web-development pattern, where the &#x27;data&#x27; returned by a browser-request comes from an index. That index is an intermediary between the actual source data&#x2F;file, and the webpage a user loads.&lt;&#x2F;p&gt;
&lt;p&gt;An example... For two work-projects, the source-truth of the scholarly data is in xml-files (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;usep-data&#x2F;tree&#x2F;master&#x2F;xml_inscriptions&#x2F;transcribed&quot; title=&quot;GitHub usep link&quot;&gt;example&lt;&#x2F;a&gt;). Knowedgeable trained folk encode data from headstones or other sources into these xml-files.&lt;&#x2F;p&gt;
&lt;p&gt;But when a user performs a search on the project&#x27;s webpage, or loads an inscription-page from the website, the server looks up info from our &lt;a href=&quot;https:&#x2F;&#x2F;solr.apache.org&#x2F;&quot; title=&quot;solr link&quot;&gt;solr&lt;&#x2F;a&gt; indexer.&lt;&#x2F;p&gt;
&lt;p&gt;Why the intermediary index? Partly because indexers are very, very fast. Also because they can deliver great search results in a way that offers a user easy and useful ways to filter results (&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Faceted_search&quot; title=&quot;facet wikipedia link&quot;&gt;&amp;quot;facets&amp;quot;&lt;&#x2F;a&gt;). And also because the most common indexers are very easy for developers to configure and query and update.&lt;&#x2F;p&gt;
&lt;p&gt;Given this small architectural tour, since the data for a web-request comes most directly from the index (not the xml files), it&#x27;s easy to see how the &amp;quot;source-of-truth&amp;quot; &lt;em&gt;could&lt;&#x2F;em&gt; be thought of as the index. If an xml-file hasn&#x27;t been indexed, it won&#x27;t appear on the website; in a way, it doesn&#x27;t exist.&lt;&#x2F;p&gt;
&lt;p&gt;Jonathan&#x27;s post focuses on a specification for saving files-and-associated-metadata to a filesystem, called &lt;a href=&quot;https:&#x2F;&#x2F;ocfl.io&#x2F;&quot; title=&quot;OCFL link&quot;&gt;OCFL&lt;&#x2F;a&gt; (&amp;quot;Oxford Common File Layout&amp;quot;). Though the uses of OCFL are not limited to repositories, it was developed from University repository-developers deliberating about, and implementing, a simple useful file-layout specification that different software-tools can use. &lt;&#x2F;p&gt;
&lt;p&gt;Because OCFL is most common in this repository context, and because repositories conceptually prioritize archival durability, OCFL data tends to be thought of as &amp;quot;source of truth&amp;quot; data in repository-architecture. &lt;&#x2F;p&gt;
&lt;p&gt;But repositories use indexers. Jonathan&#x27;s post illuminates competing visions of whether the OCFL storage-layer, or the indexer (or some correlative intermediary) should be considered the &amp;quot;source of truth&amp;quot; -- and the implications for decisions. My take is a bit different than his about the increased technical challenges of an OCFL-first source-of-truth, vs an intermediary-first source-of-truth -- but the main take-away for me is that it&#x27;s important to be very clear on what the purposes are for the two layers.&lt;&#x2F;p&gt;
&lt;p&gt;For the &lt;a href=&quot;https:&#x2F;&#x2F;repository.library.brown.edu&#x2F;studio&#x2F;&quot; title=&quot;BDR link&quot;&gt;BDR&lt;&#x2F;a&gt; (Brown Digital Repository), we want to ensure that if some disaster struck, and all the the BDR&#x27;s infrastructure went down, but we still had the offsite-OCFL-file-data (and our indexer-code in GitHub), we could reconstitute the BDR.&lt;&#x2F;p&gt;
&lt;p&gt;But other projects may lend themselves to a &lt;em&gt;shared&lt;&#x2F;em&gt; source-of-truth between the two key layers. &lt;&#x2F;p&gt;
&lt;p&gt;For a current work project, the main data-source is a FileMaker-Pro database. That data is exported, and indexed; the website accesses the index. A long-term project is underway to scan this collection&#x27;s materials, and put them in the BDR. Once there, we&#x27;ll naturally want to link to the relevant BDR-content from the website. How to do that?&lt;&#x2F;p&gt;
&lt;p&gt;For various reasons, we&#x27;ve decided not to add BDR links to the FileMaker-Pro database. Instead, we&#x27;ll add those urls directly to the index. So there will be very useful data in the index that&#x27;s not in the foundational source-data.&lt;&#x2F;p&gt;
&lt;p&gt;But that&#x27;s ok -- the important thing is to be clear and deliberate about what data is going where, for what reasons. And to be clear about how a useful website can be reconstituted from that source-data if needed. These are issues that we developers are &lt;em&gt;familiar&lt;&#x2F;em&gt; with, but given time and resource constraints, may not always think through deeply and document clearly. Which is why I so appreciate Jonathan&#x27;s post: it raises a variety of useful issues to work through intentionally.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>approaches to testing</title>
        <published>2021-09-17T00:00:00+00:00</published>
        <updated>2021-09-17T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/art-of-testing/" type="text/html"/>
        <id>https://bspace.us/posts/art-of-testing/</id>
        
        <content type="html">&lt;p&gt;&lt;em&gt;The evolution of testing -- what&#x27;s lost and gained?&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;I have a project in which I&#x27;m parsing data.&lt;&#x2F;p&gt;
&lt;p&gt;One useful principle of testing is to have a discrete piece of functionality tested. And the most direct way to do that for parsing is to pass in source-data, and specify a clear assertion. &lt;&#x2F;p&gt;
&lt;h2 id=&quot;simple-and-direct&quot;&gt;simple and direct&lt;&#x2F;h2&gt;
&lt;p&gt;I began that way: &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;parse_alma_annex_requests_code&#x2F;blob&#x2F;8109bdbf6b9ff3dd609d8d2c5c7775d72ad3de10&#x2F;tests.py#L156&quot;&gt;Here&#x27;s&lt;&#x2F;a&gt; the beginning of Parser testing.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;parse_alma_annex_requests_code&#x2F;blob&#x2F;8109bdbf6b9ff3dd609d8d2c5c7775d72ad3de10&#x2F;tests.py#L241-L246&quot;&gt;Here&#x27;s&lt;&#x2F;a&gt; the first iteration of parsing a patron note -- although the test was originally called, simply &lt;code&gt;test_parse_patron_note()&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;That happened to be for a physical item; shortly thereafter I needed to parse the note for a digital item. &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;parse_alma_annex_requests_code&#x2F;blob&#x2F;8109bdbf6b9ff3dd609d8d2c5c7775d72ad3de10&#x2F;tests.py#L248-L253&quot;&gt;Here&lt;&#x2F;a&gt; is the iteration that tested for that. &lt;&#x2F;p&gt;
&lt;p&gt;Implementing that second test, I renamed the first example to show that the test was for a physical item, and named the second test to show that it was testing a digital item. I could have passed just the specific item-xml or item-xml-object to each test. In some ways that would have been simpler and &amp;quot;purer&amp;quot;. But the real data for this project comes in a file containing multiple kinds of items, and I was going to be using the items for different kinds of tests (not just notes), so I figured I&#x27;d have one main test-file that would contain a variety of items to use for the tests. (Though this does add a slight dependency to the test -- file loading -- and dependences are frowned upon.)&lt;&#x2F;p&gt;
&lt;p&gt;In the two examples shown so far, I chose, from the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;parse_alma_annex_requests_code&#x2F;blob&#x2F;8109bdbf6b9ff3dd609d8d2c5c7775d72ad3de10&#x2F;test_dirs&#x2F;static_source&#x2F;BUL_ANNEX-sample.xml&quot;&gt;source-data&lt;&#x2F;a&gt; being tested, the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;parse_alma_annex_requests_code&#x2F;blob&#x2F;8109bdbf6b9ff3dd609d8d2c5c7775d72ad3de10&#x2F;tests.py#L244&quot;&gt;first list item&lt;&#x2F;a&gt; for the physical-note test, and the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;parse_alma_annex_requests_code&#x2F;blob&#x2F;8109bdbf6b9ff3dd609d8d2c5c7775d72ad3de10&#x2F;tests.py#L251&quot;&gt;sixth list item&lt;&#x2F;a&gt; for the digital-note test.&lt;&#x2F;p&gt;
&lt;p&gt;This is all reasonably forthright. The nice thing about this is that, coming back to this code in future weeks or months, and running the tests, I&#x27;d see from the terminal output, when running the test-suite, the explicit &lt;code&gt;test_parse_patron_note_physical()&lt;&#x2F;code&gt; and &lt;code&gt;test_parse_patron_note_digital()&lt;&#x2F;code&gt; tests. That&#x27;s really useful when revisiting code.&lt;&#x2F;p&gt;
&lt;p&gt;But the more edge-cases that arise, the benefits of this explicitness quickly, for me, feel outweighed by the duplication. I could have half-a-dozen explicit tests for parsing just the notes field for physical items, another half-dozen for digital items, and have lots of very specific tests for all the other parsing.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;scalable&quot;&gt;scalable&lt;&#x2F;h2&gt;
&lt;p&gt;In this and other projects, in this situation, I&#x27;ve moved to a different pattern: a &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;parse_alma_annex_requests_code&#x2F;blob&#x2F;8109bdbf6b9ff3dd609d8d2c5c7775d72ad3de10&#x2F;tests.py#L221-L239&quot;&gt;single test&lt;&#x2F;a&gt; for parsing the target field (in this case the note). This single test first loads up an array of items, an array of expectations, and then iterates through the array, so the single test in this case is actually testing eight variations.&lt;&#x2F;p&gt;
&lt;p&gt;This has some real advantages -- it&#x27;s very scalable, since adding a new source-data item simply involves adding an expectation to this note, and the other parsed fields. I might be adding the new item because I&#x27;m aware of an edge-case for parsing, say, the item-barcode, and by having to also list the note expectation, I might end up catching some error I hadn&#x27;t been aware of.&lt;&#x2F;p&gt;
&lt;p&gt;BUT... there is loss with the gain. I need to view the comments (or the source-data) to see&#x2F;remember that I&#x27;m parsing physical vs digital items. (Might there be another digital item that I forgot to indicate via a comment?) And I&#x27;m not going to see those comments in the test-output. &lt;&#x2F;p&gt;
&lt;p&gt;I just remembered long ago implementing something like this with an additional field in the array. Instead of just handing two-elements in each loop iteration (the source-item-data, and the expectation) -- I also had a comment that was printed, too. That would restore some of the useful specificity of output -- and on a failure, allow me to target, more quickly, the location of the error.&lt;&#x2F;p&gt;
&lt;p&gt;This example of gain&#x2F;loss refactoring is a miniscule one -- but it reveals aspects of the decision-making in programming that I love.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>shibboleth and fedora</title>
        <published>2010-01-16T00:00:00+00:00</published>
        <updated>2010-01-16T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/shib-and-fedora/" type="text/html"/>
        <id>https://bspace.us/posts/shib-and-fedora/</id>
        
        <content type="html">&lt;p&gt;&lt;em&gt;[2023 update -- our repository architecture has changed significantly (I&#x27;ll post about it sometime), so this post (like so many old tech-posts) is for posterity. 🙂 ]&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;I don&#x27;t work directly on &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fedora_(software)&quot;&gt;Fedora&lt;&#x2F;a&gt; (our repository software), but am very familiar with it due to my work with a programmer who does, and because I&#x27;ve worked on a &lt;a href=&quot;http:&#x2F;&#x2F;www.djangoproject.com&#x2F;&quot;&gt;django&lt;&#x2F;a&gt; front-end for ingestion of items into fedora, as well as fedora-apis. My role in fedora work is more akin to the &#x27;corner-man&#x27; in boxing. Together the boxer and I strategize about the opponent, his defenses and threats to our plans, and devise approaches to deal with evolving challenges. We cross ourselves, the fedora programmer goes into the ring, and between rounds I provide moral support, bandage wounds, and, because of my distance from actual battle, sometimes have useful ideas for the next round. This analogy&#x27;s negativity toward the Fedora software is appropriate; to use another: We&#x27;ve bought a car that, in hindsight, I wouldn&#x27;t recommend to others, but that we&#x27;re committed to getting some terrific mileage out of.&lt;&#x2F;p&gt;
&lt;p&gt;So, it&#x27;s been a tough fight, but our boxer is quick, has impressive endurance, and we believe we&#x27;ll come out on top.&lt;&#x2F;p&gt;
&lt;p&gt;Fedora authorization is one round in which we think we&#x27;ve scored well.&lt;&#x2F;p&gt;
&lt;p&gt;Fedora comes bundled with an authorization piece called &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;XACML&quot;&gt;XACML&lt;&#x2F;a&gt;. I don&#x27;t know if it&#x27;s due to xacml, or fedora&#x27;s implementation of it, but from what I gather indirectly, it&#x27;s terrifying enough that few use it, and it is, in fact, scheduled to be augmented in a future release with a new Great Hope: &lt;a href=&quot;https:&#x2F;&#x2F;wiki.lyrasis.org&#x2F;display&#x2F;FEDORA34&#x2F;FeSL+Authentication&quot;&gt;FeSL&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;But if you want to go into production &lt;em&gt;now&lt;&#x2F;em&gt;, what to do? The dearth of published authentication&#x2F;authorization &#x27;live&#x27; solutions is why, as I understand it, so many fedora installations are either completely open (all objects public), or completely locked down for internal use.&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;ve assumed we would use some sort of wrapper around fedora, to authenticate against &lt;a href=&quot;http:&#x2F;&#x2F;shibboleth.internet2.edu&#x2F;&quot;&gt;Shibboleth&lt;&#x2F;a&gt;, with which our university is slowly moving forward. Shib&#x27;s lack of logout capability, and the resultant assumption that users will happily quit their browser to logout, would seem quaintly amusing if it weren&#x27;t true -- but that is another topic entirely, and single sign-on is certainly convenient. Not long ago we began to tackle how, specifically, to implement shib&#x2F;fedora authorization.&lt;&#x2F;p&gt;
&lt;p&gt;Recently someone described to me an authorization approach the &lt;a href=&quot;http:&#x2F;&#x2F;www.muradora.org&#x2F;muradora&quot;&gt;muradora&lt;&#x2F;a&gt; folk took. I haven&#x27;t looked at any documentation myself, but I was told that they wrote a servlet filter that takes a submitted name and password, and passes it to a non-centralized custom ldap server that exists only for the purpose of allowing fedora&#x27;s built in ldap-xacml code to handle authentication. (For those unfamiliar: a java servlet filter acts as a front layer of a java webapp through which incoming requests and outgoing responses must pass, and can be modified.) &lt;&#x2F;p&gt;
&lt;p&gt;A few of us heard this and had divergent reactions. It sounded like a hack, which caused some to dismiss the approach. Personally, being quite partial to hacks that work around monolithic software obstacles, I thought the hack smacked of ingenious creativity and was worth further examination. I was indulged; the result: our corner has devised an approach that initial testing indicates will work well.&lt;&#x2F;p&gt;
&lt;p&gt;First, some necessary background info... &lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Our University shib implementation is integrated with &lt;a href=&quot;http:&#x2F;&#x2F;www.internet2.edu&#x2F;grouper&#x2F;&quot;&gt;Grouper&lt;&#x2F;a&gt;. I think grouper is, or at least historically has been, a separate project from shibboleth, but they work together brilliantly. Upon shib-login, a list of the groups to which the user belongs is accessible to the server via the shib &#x27;is-member-of&#x27; header field.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Our implementation of fedora item ingestion involves creating a &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;METS&quot;&gt;METS&lt;&#x2F;a&gt; record that contains a bunch of item-info -- including a rights segment. The rights segment contains a series of entries, each one listing an identity (a shib is-member-of group) and a permission. Example (content, not format): identity=&#x27;chemistry-department&#x27; &amp;amp; permission=&#x27;view_item&#x27;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The mets record is handed to an ingester that converts the mets xml to &lt;a href=&quot;http:&#x2F;&#x2F;www.fedora-commons.org&#x2F;download&#x2F;2.0&#x2F;userdocs&#x2F;digitalobjects&#x2F;introFOXML.html&quot;&gt;FOXML&lt;&#x2F;a&gt;, then fedora grabs the object (we&#x27;re using the &#x27;managed&#x27; option at the moment), and the java messaging built into fedora fires off a message to a listener that indexes (via &lt;a href=&quot;http:&#x2F;&#x2F;lucene.apache.org&#x2F;solr&#x2F;&quot;&gt;Solr&lt;&#x2F;a&gt;) parts of the foxml record, including the rights information.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;So, our approach: create a fedora servlet filter that reads the shib groups&#x2F;identities, then does a solr search to see if the object being requested has a &#x27;view&#x27; permission for any of the identities in the request&#x27;s shib is-member-of header. If so, the request is allowed through; if not; it is blocked. If no shib-identity is found, the servlet filter will only yield objects with &#x27;public&#x27; view_item permissions. &lt;&#x2F;p&gt;
&lt;p&gt;The beauty of this is that fedora-access can be fully open to the internet while still allowing authorized access for those objects that require it. Further, this solution offers reasonable hope that it will survive fedora upgrades, since the servlet, though a part of the fedora webapp, is somewhat of a separate layer in front of the app. Further, by adding more granular permissions (at the moment permissions are at the object-level; they could be at the data-stream level) -- or simply by a bit of extra programming in the servlet-filter -- we could allow, say, the public to access low and medium-resolution images, but allow, say, faculty to access high-resolution images.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I&#x27;ll keep this paragraph updated...&lt;&#x2F;em&gt; Our intrepid programmer has figured out where to insert the custom servlet filter, has worked with our systems person to hook up an initial apache&#x2F;tomcat connection so as to allow the shib installation on apache to pass its headers through to tomcat, and confirmed the filter&#x27;s detection of the shib identity header information. A nice side-effect of installing shib on apache rather than tomcat directly is that we can allow programmatic access to port 8080.&lt;&#x2F;p&gt;
&lt;p&gt;The bell has rung; the next round begins. We cross our fingers, and the programmer heads into the ring once again.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>recursion</title>
        <published>2008-10-26T00:00:00+00:00</published>
        <updated>2008-10-26T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/recursion/" type="text/html"/>
        <id>https://bspace.us/posts/recursion/</id>
        
        <content type="html">&lt;p&gt;After writing the code below recently, I searched out a few cohorts at work to share the joy, but it was late and no one was around...&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;  def makeHierarchicalFolderList( folder_object_list, return_list=[], indent=&amp;#39;&amp;#39; ):    
&lt;&#x2F;span&gt;&lt;span&gt;       &amp;#39;&amp;#39;&amp;#39;    
&lt;&#x2F;span&gt;&lt;span&gt;       - Called by: views.uploader3()    
&lt;&#x2F;span&gt;&lt;span&gt;       - Purpose: to create a list of community-folders (for upload form) with indents indicating hierarchical relationship. Will likely be replaced by better user-interface.    
&lt;&#x2F;span&gt;&lt;span&gt;       &amp;#39;&amp;#39;&amp;#39;    
&lt;&#x2F;span&gt;&lt;span&gt;                               
&lt;&#x2F;span&gt;&lt;span&gt;       for folder in folder_object_list:    
&lt;&#x2F;span&gt;&lt;span&gt;            folder.name = &amp;#39;%s%s&amp;#39; % ( indent, folder.name )    
&lt;&#x2F;span&gt;&lt;span&gt;            return_list.append( folder )    
&lt;&#x2F;span&gt;&lt;span&gt;                
&lt;&#x2F;span&gt;&lt;span&gt;            # check for children    
&lt;&#x2F;span&gt;&lt;span&gt;            children_count = folder.communityfolder_set.all().count()    
&lt;&#x2F;span&gt;&lt;span&gt;                
&lt;&#x2F;span&gt;&lt;span&gt;            # handle check-results    
&lt;&#x2F;span&gt;&lt;span&gt;            if children_count == 0:    
&lt;&#x2F;span&gt;&lt;span&gt;                 pass    
&lt;&#x2F;span&gt;&lt;span&gt;            else:    
&lt;&#x2F;span&gt;&lt;span&gt;                 children_object_list = folder.communityfolder_set.all()    
&lt;&#x2F;span&gt;&lt;span&gt;                 indent = indent + &amp;#39;-&amp;#39;    
&lt;&#x2F;span&gt;&lt;span&gt;                 makeHierarchicalFolderList( children_object_list, return_list, indent=indent )    
&lt;&#x2F;span&gt;&lt;span&gt;                 indent = indent[1:] # since we&amp;#39;re at the end of a processing chain, remove the indent    
&lt;&#x2F;span&gt;&lt;span&gt;                     
&lt;&#x2F;span&gt;&lt;span&gt;       return return_list    
&lt;&#x2F;span&gt;&lt;span&gt;                
&lt;&#x2F;span&gt;&lt;span&gt;       # end def makeHierarchicalCommunityFolderList()    
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What enthused me so was the line a few up from the bottom, where I call the very function in which this line resides. This is called recursion. There&#x27;s a wonderful slightly mysterious inverted mobius-strip-like quality to recursion, except that if done right, processing doesn&#x27;t continue on forever.&lt;&#x2F;p&gt;
&lt;p&gt;The code above neatly meets the needs of a project I&#x27;m working on: to prepare a hierarchical listing of folders. Not shown is an initial step in which a query is made for a user-specific list of &#x27;top-level&#x27; folders -- that is, folders which do not have a parent folder. For each folder in this list, the folder is first appended to a sort of global list-of-folders-to-return. Then a check is made to see if the folder has any children. If so, those child-folders are selected, and passed to the function itself. So for each top-level folder, a processing-chain begins that might be very, very long, or might be very short. But each processing-chain does terminate, shifting to examine the next sibling folder, and, when there are no more sibling-folders in the lowest-level generation, shifting back upward a generation to examine and process the next sibling-folder.&lt;&#x2F;p&gt;
&lt;p&gt;I use recursion infrequently enough that it sort of gets buried in my toolbox. I forget about it and from habit reach for other tools first that often do the looping job well-enough. Utilizing looping-logic is a fundamental part of programming. Where a built-in looping structure doesn&#x27;t directly solve looping needs, I most often use a Controller-pattern solution to a looping challenge. That is, I&#x27;ll have a controller block of code prepare a list of items that need to be looped through, and perhaps set some variables to hold the results of processing, and then call a separate function that handles the actual looping. Sometimes for more complex situations the called looping code can itself call another separate block of looping code. So it is possible to handle some situations, for which recursion might be ideal, with other techniques. But not all situations -- when my usual looping implementation begins feeling overly complex, that&#x27;s often a sign to root around and dust off the recursion tool.&lt;&#x2F;p&gt;
&lt;p&gt;Despite some left-over 1960&#x27;s geek-stereotypes about programming being a boring left-brain process, there can be elegance and deep beauty in programming. There are numerous ways to approach and solve a challenge, any of which may work &#x27;well-enough&#x27;. Good programmers strive for solutions that are simplest and clearest, and when the right technique lends itself to beautifully simple code, one feels like an artist.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>nice lightweight SOA implementation</title>
        <published>2008-05-18T00:00:00+00:00</published>
        <updated>2008-05-18T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/nice-soa-implementation/" type="text/html"/>
        <id>https://bspace.us/posts/nice-soa-implementation/</id>
        
        <content type="html">&lt;p&gt;I&#x27;ve evangelized &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Service-oriented_architecture&quot;&gt;service-oriented architecture&lt;&#x2F;a&gt; (SOA) &lt;a href=&quot;https:&#x2F;&#x2F;bspace.us&#x2F;posts&#x2F;moving-code-onto-network&#x2F;&quot;&gt;before&lt;&#x2F;a&gt;. &lt;&#x2F;p&gt;
&lt;p&gt;To review, briefly and roughly: SOA promotes decoupled services. For example, a Fahrenheit-to-Celsius converter would likely be implemented as a web-service, instead of as a function&#x2F;method embedded&#x2F;tied into some bigger program. The benefits of this are multiple: 1) The service can be written in any programming language, and accessed by other services written in different languages. 2) SOA makes the idealized promise of code-reuse a reality.&lt;&#x2F;p&gt;
&lt;p&gt;I have a programmer friend who works for a large corporation who is familiar with implementing SOA using industrial-scale best-practices; I&#x27;m familiar with implementing it in a lightweight, seat-of-the-pants fashion.&lt;&#x2F;p&gt;
&lt;p&gt;Over the past year+ I&#x27;ve created well over a dozen or so SOA web-services for different projects. But I recently implemented one I put some best-practice effort into that&#x27;ll be a model for my future SOA work. Some links:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;[2023 update -- the march of progress has resulted in the retirement of these services, so no active links. Sorry!]&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;http:&#x2F;&#x2F;library.brown.edu&#x2F;services&#x2F;language_translator&#x2F;&lt;&#x2F;code&gt;
&lt;code&gt;http:&#x2F;&#x2F;library.brown.edu&#x2F;services&#x2F;language_translator&#x2F;api_v1&#x2F;code_eng&#x2F;&lt;&#x2F;code&gt;
&lt;code&gt;http:&#x2F;&#x2F;library.brown.edu&#x2F;services&#x2F;language_translator&#x2F;api_v1&#x2F;all&#x2F;&lt;&#x2F;code&gt;
&lt;code&gt;http:&#x2F;&#x2F;library.brown.edu&#x2F;services&#x2F;language_translator&#x2F;list&#x2F;&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;What I like about this one...&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The api urls offer &#x27;discovery&#x27; via embedding, in the built-in returned data, contact and documentation information. Having just one of these pieces of info would be great; having both is particularly nice because web urls and staff change over time. Why is this useful? If someone is looking at the code that calls this service 5 years from now, and if I&#x27;m not around, the documentation will provide info on some extra features of the service that otherwise wouldn&#x27;t be apparent if, say, the web-service just returned the word &#x27;English&#x27;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The api urls are &#x27;hackable&#x27;, another way of enhancing discovery. One can intuitively try entering a code other than &#x27;enk&#x27; to see what comes up (like &#x27;&lt;a href=&quot;http:&#x2F;&#x2F;library.brown.edu&#x2F;services&#x2F;language_translator&#x2F;api_v1&#x2F;code_tlh&#x2F;&quot;&gt;tlh&lt;&#x2F;a&gt;&#x27;). Also, reasonably appropriate things happen if one lops off increasing sections of the url (in this case, redirects to documentation pages).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The api urls are versioned. Key:value pairs can be added to this api -- but the existing key:value pairs must never be changed. The reason is that post-release, I don&#x27;t know who&#x27;s using it for what, thus I have to assume any changes could break someone&#x27;s app. So if I want to change the label &#x27;response&#x27; to &#x27;language&#x27;, and deliver it in xml, I can leave the existing one as is, and label the new one &#x27;api_v2&#x27;.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;All these urls utilize server-caching. This is an implementation rather than a design feature, but worth mentioning. &lt;a href=&quot;http:&#x2F;&#x2F;www.djangoproject.com&#x2F;&quot;&gt;Django&lt;&#x2F;a&gt; offers a flexible and easy-to-use &lt;a href=&quot;http:&#x2F;&#x2F;www.djangoproject.com&#x2F;documentation&#x2F;cache&#x2F;&quot;&gt;caching feature&lt;&#x2F;a&gt;; I have it set so that the list and api urls only have to hit the database once a day, no matter how many times the urls are hit. Further, django&#x27;s caching is intelligent: its response includes &#x27;Cache-Control&#x27;, &#x27;Etag&#x27;, and &#x27;Expires&#x27; http-headers so that a browser or well-designed code &lt;em&gt;doesn&#x27;t even have to call the web-service again&lt;&#x2F;em&gt; to redisplay the data. Nice. This would be particularly important and useful for something like RSS feeds. &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Good info...&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A terrific, hands-on review-resource on http-headers: The &lt;a href=&quot;http:&#x2F;&#x2F;www.diveintopython.org&#x2F;http_web_services&#x2F;index.html&quot;&gt;web-services chapter&lt;&#x2F;a&gt; of Mark Pilgrims &#x27;Dive Into Python&#x27; &lt;a href=&quot;http:&#x2F;&#x2F;www.diveintopython.org&#x2F;index.html&quot;&gt;website&lt;&#x2F;a&gt; &amp;amp; &lt;a href=&quot;http:&#x2F;&#x2F;www.worldcat.org&#x2F;oclc&#x2F;56366433&quot;&gt;book&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Many of the features of this language_translator web-service were informed by the &lt;a href=&quot;http:&#x2F;&#x2F;www.worldcat.org&#x2F;oclc&#x2F;82671871&quot;&gt;book&lt;&#x2F;a&gt; &#x27;RESTful Web Services&#x27;, by Richardson &amp;amp; Ruby. Some parts are a bit dense, but it&#x27;s chock-full of terrific detailed info and food for thought. I came across it after having written a half-dozen or so SOA web-services, each one a little different and better, and it directly addressed many issues I had begun to think about or saw referenced via web-research.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;em&gt;[Acknowledgements to Peter Murray&#x27;s&lt;&#x2F;em&gt; &lt;a href=&quot;http:&#x2F;&#x2F;dltj.org&#x2F;article&#x2F;defining-soa-by-analogy&#x2F;&quot;&gt;&lt;em&gt;article&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; &lt;em&gt;and Richard Akerman&#x27;s Access_2006&lt;&#x2F;em&gt; &lt;a href=&quot;http:&#x2F;&#x2F;scilib.typepad.com&#x2F;science_library_pad&#x2F;access2006&#x2F;&quot;&gt;&lt;em&gt;presentation&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; &lt;em&gt;that first inspired my SOA thinking.]&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>weighted randomization</title>
        <published>2008-04-16T00:00:00+00:00</published>
        <updated>2008-04-16T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/weighted-randomization/" type="text/html"/>
        <id>https://bspace.us/posts/weighted-randomization/</id>
        
        <content type="html">&lt;p&gt;Many years ago one of my children hit a wall with Math in elementary school. He had always been bright, and quick to pick things up, so this was something of a surprise to him as well as to me. His class was in the early stages of learning multiplication, and it turned out that he had initially been able to add numbers in his head quickly enough that he hadn&#x27;t needed to memorize the times-tables. This worked fine for him with lower numbers like 5x2, but began to break down pretty quickly with higher numbers like 9x7 and especially 23x76.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;flashcard-app&quot;&gt;Flashcard app&lt;&#x2F;h3&gt;
&lt;p&gt;So I ended up doing something I had sworn I&#x27;d never do: I created a flashcard program on the computer to help him memorize his basic times-tables. I had always thought that using computer programs for rote memorization was a travesty -- knowing that computers could be used for interesting and mind-expanding purposes rather than boring, mind-numbing ones. But this became a fascinating project. I started out implementing it in &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Filemaker_Pro&quot;&gt;FileMaker Pro&lt;&#x2F;a&gt;, which I had begun using extensively for some database projects, and eventually reimplemented the program in &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;REALbasic&quot;&gt;REALbasic&lt;&#x2F;a&gt;, a wonderful program (at least at the time; I haven&#x27;t used it in years) that introduced me to object-oriented programming, and through the sheer elegance of its interface and structure nurtured my growing sense that programming was about Art in addition to Logic.&lt;&#x2F;p&gt;
&lt;p&gt;In addition to wanting to present a nice interface, I also knew that I wanted the questions presented to my son to flow in such a way that he would be quizzed more often on the questions he answered incorrectly, and less often on the ones he answered correctly. In any given work-session, I also wanted him to be able to work with a narrow slice of the whole set of &#x27;difficult&#x27; problems so that he would perceive some sense of gaining mastery over material.&lt;&#x2F;p&gt;
&lt;p&gt;To clarify this last point, imagine a problem set of 10,000 questions, 5,000 of which are very easy, and 5,000 of which are very hard. Imagine you sit down to a 10-minute &#x27;memorization-session&#x27;. If the program utilizes a very simple algorithm which chooses &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Randomness&quot;&gt;randomly&lt;&#x2F;a&gt; from among the 5,000 difficult questions, chances are that after the 10 minutes you will have learned nothing and will be quite discouraged: you&#x27;ll likely not have seen the same question twice, and you&#x27;ll have answered everything wrong. This would be bad enough if you were an adult committed to learning the material, but if you were a kid in elementary school, this would be likely to crush any flickering desire to learn the material.&lt;&#x2F;p&gt;
&lt;p&gt;And I wanted my program to be fun.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;details&quot;&gt;Details&lt;&#x2F;h3&gt;
&lt;p&gt;My solution was to use what I call &#x27;weighted-randomization&#x27;. Sometime I&#x27;ll do a thorough search for the files I used those many years ago to see if I can find the code I created -- for posterity, amusement, and fond reflection. The basic idea consisted of two steps. First, from among all the... I guess 169 possible times-table queries (0x0 through 12x12), I chose a small subset: 10 as I recall, although eventually I made this number selectable via a preferences-pane (remember, I made this for a young kid, and assumed two 5-minute practice-sessions a day -- the latter one being optional but often completed because the app was fun). Second, I presented the queries. But of course the joy was in the details.&lt;&#x2F;p&gt;
&lt;p&gt;For the selection-step, my recollection is that I iterated through each possibility, and assigned it a &#x27;selection-number&#x27;, then sorted the list on selection-number and took the top 10. Before I describe the selection-number, I must first note that each possible query was initially assigned a &#x27;score&#x27; of 0. When a query was answered correctly, the score was incremented; when answered incorrectly, the score was decremented. I eventually put the increment and decrement values into the app&#x27;s preferences-pane to play around with their effect on the operation of the application, and as I recall usually had them set to increment correct answers by 1, and decrement incorrect answers by 2.&lt;&#x2F;p&gt;
&lt;p&gt;So why the selection-number rigamarole? Why not just sort on score, and take the 10 lowest numbers? That certainly would achieve the goal of presenting the user with the most-problematic problem-set. I did do that initially, but added the selection-number for two reasons. First, the simple presentation of only the hardest problems felt, well... boring. Second, I thought if I occasionally threw in some problems &#x27;mostly&#x27; known, I would encourage crucial reinforcement to take place. And if one or two of the problem-set were &#x27;easy&#x27;, well, those queries&#x27; scores would rapidly increase and be less likely to be selected as part of the subset next time. Thus the selection-number. I don&#x27;t remember the exact details, which I changed and experimented with extensively, but the basic idea: I took the lowest-score and the highest score, and split the range between them into, say, 10 equal segments. I then iterated through the queryset. For each score, I determined the segment it belonged to, then created a certain number of random-numbers, took the highest one, and assigned that as the selection-number. A more specific concrete example... Say the lowest score was -25 and the highest score was 5. That&#x27;s a difference of 30. Splitting that into 10 segment-ranges yields segment ranges of 3 values. Thus the bottom segment-range would be -25 through -23, while the top segment would be 3 through 5. During the iteration step, if I came across -23 (in selection-range &#x27;10&#x27;), I would create &#x27;10&#x27; random numbers, and the highest one would become that query&#x27;s selection-number. If I came across &#x27;3&#x27; (in selection-range &#x27;1&#x27;), I would create &#x27;1&#x27; random number; it would become that query&#x27;s selection-number. Thus sorting then on selection-number and choosing the ten highest numbers would usually offer a subset of all queries consisting of mostly the hardest queries, mixed with some somewhat-hard queries, with an occasional easy query thrown in. Beautiful. Again, I don&#x27;t remember the specific details, and do remember that I played frequently with the number of ranges and the number of random-numbers assigned for each range, but this description reflects the general approach to the slice-selection step.&lt;&#x2F;p&gt;
&lt;p&gt;The program was a hit, and did exactly what I had hoped; it helped my child memorize his times-tables. Shortly after I built it, I was immersed in learning Italian, and realized that with just a few tweaks this would be a terrific tool to help me memorize vocabulary. That also worked well, especially the ability to focus a review-sesion on a subset of all the words, because I built up a vocabulary set of hundreds of words. But abstracted from the tool, I kept ruminating on what made &#x27;weighted-randomization&#x27; so compelling.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-idea&quot;&gt;The idea&lt;&#x2F;h3&gt;
&lt;p&gt;The concept binds together polar notions in a way that feels &#x27;right&#x27;. Variety, as we&#x27;ve all heard, is the spice of life; morphing random-chance into likelihood offers possibilities for combining intentionality with variability to create joyful experience, as any gamer knows. The game &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dungeons_and_dragons&quot;&gt;Dungeons &amp;amp; Dragons&lt;&#x2F;a&gt; wonderfully codified realms of probability in spirals of detail useful to both the casual gamer and the addict: a strong character will be more &#x27;likely&#x27; to defeat a weaker character, but more granularly, a particular delivery of a particular blow will be more or less likely to be successful based on the quality of the attacking weapon and the defending shield, the skill of the attacker and defender, etc. The &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dice#Non-cubical_dice&quot;&gt;varied dice&lt;&#x2F;a&gt; used to calculate these percentages seem themselves talismans. But on a simpler level, any player of &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Risk_%28game%29&quot;&gt;Risk&lt;&#x2F;a&gt; or &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Backgammon&quot;&gt;Backgammon&lt;&#x2F;a&gt; perceives these same issues. The roll of the dice is pure chance, but the strength of one&#x27;s position makes the outcome of a battle or game dependent on the same order-and-chance qualities embodied in weighted-randomization.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;making-the-world-a-better-place&quot;&gt;Making the world a better place&lt;&#x2F;h3&gt;
&lt;p&gt;I find it interesting to think about applying randomization to other systems. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;http:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20080830093825&#x2F;http:&#x2F;&#x2F;www.llamagraphics.com&#x2F;LB&#x2F;index.php&quot;&gt;LifeBalance&lt;&#x2F;a&gt; is a wonderful little to-do list program I miss using since I gave up my Palm for an &lt;a href=&quot;http:&#x2F;&#x2F;www.apple.com&#x2F;iphone&#x2F;&quot;&gt;iPhone&lt;&#x2F;a&gt;. I don&#x27;t have direct knowledge of its internals, but I suspect it incorporates weighted-randomization in it&#x27;s preparation of one&#x27;s task-list. One part of the program offers the ability to define broad areas of life (i.e. work, maintaining friendships, family-life, etc.) and assign a rough percentage of time one would ideally like to devote to each area. Since to-do tasks end up being subsets of these areas, and since each task can be assigned a rough amount of time it will take to accomplish, the program tracks how much time is &lt;em&gt;actually&lt;&#x2F;em&gt; being expended in the broad areas, and optionally adjusts the current to-do list to maintain the preferred balance. The result is that there may be occasions in which a task of a slightly lower priority can appear higher on a to-do list than a task with a higher priority, if the lower-priority task will better-serve the less-immediate goal of achieving the life-area balance specified. This approach could conceivably be implemented using algorithms that don&#x27;t utilize weighted-randomization, but this is just the kind of situation that weighted-randomization would be good for -- injecting a bit of flexibility into a system while still maintaining overall goals.&lt;&#x2F;p&gt;
&lt;p&gt;As a final thought experiment, imagine possibilities for injecting weighted-randomization into political systems.&lt;&#x2F;p&gt;
&lt;p&gt;I have a vague memory from a college class, likely jumbled by time, of hearing that in 15th Florence, a cohort of possible city-council leaders was chosen from among the populace much like those chosen for jury-duty today. As I recall, each individual in the cohort was then voted on by the populace, but only whether the individual was fit to serve: a yes or no vote. If a person received enough yes-votes, his name was put into a hat from which the new leaders were drawn at random. This unusual form of weighted-randomization suggests that when injected into political systems, it might reduce corrupting influences and by inference improve quality. Usually, and reasonably, years-of-service or merit-evaluations or test-scores are the institutional barriers to corruption. Weighted-randomization could be another tool worth exploring.&lt;&#x2F;p&gt;
&lt;p&gt;Imagine that of all bills a legislative committee debates publicly, 80% are selected for debate according to usual political processes, and 20% via a weighted-randomization scheme akin to my math flash-card program (i.e., perhaps a manual ranking of preference followed by randomizations based on those rankings). Obviously no one would want chance to factor into whether a bill actually becomes law, but since so many good ideas die for want of being scheduled for committee debate (often for questionable political reasons), injecting a bit of weighted-randomization into such a process could be a good thing, certainly worth trying.&lt;&#x2F;p&gt;
&lt;p&gt;I may add to this post other realms in which weighted-randomization might offer systemic improvements. Feel free to suggest ideas; I may post a few of them here.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>moving code onto the network</title>
        <published>2008-02-09T00:00:00+00:00</published>
        <updated>2008-02-09T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/moving-code-onto-network/" type="text/html"/>
        <id>https://bspace.us/posts/moving-code-onto-network/</id>
        
        <content type="html">&lt;p&gt;In 2004, while in my masters program, deeply immersed in java object-oriented programming, I saw the potential benefits of code re-use that classes offer. I envisioned over time building up libraries of class-objects; by accessing them in future projects, I expected to be more and more productive.&lt;&#x2F;p&gt;
&lt;p&gt;Code-reuse never quite worked out that way, though. What I&#x27;ve tended to do for new projects has been to copy a similar class from a previous project, paste it into the new project, weed out unnecessary attributes and methods, and add new code. In a way this makes sense: though I lose out on &#x27;pure&#x27; code-reuse, I gain by having all code for a project together. That&#x27;s nice for version-control and portability, and isolation of concerns in that I don&#x27;t have to worry that a change in a class in one project will have unintended consequences in another project.&lt;&#x2F;p&gt;
&lt;p&gt;But reading a while back about service-oriented-architecture, and shortly thereafter having a need to code a couple of lines in python that I had just coded in php a day or two earlier -- the benefits of moving code into RESTful web-services, that is: moving it onto the network, became apparent.&lt;&#x2F;p&gt;
&lt;p&gt;I do that all the time now. Just last week I had a need to convert between 10 and 13-digit isbns -- for the second time in a recent project, so rather than coding the conversion directly in the program at hand I put it into a webservice.&lt;&#x2F;p&gt;
&lt;p&gt;In this shift, I&#x27;ve finally realized that goal of code reuse, while still being able to maintain the version-control and isolation of concerns benefits of focusing on my specific project at hand.&lt;&#x2F;p&gt;
&lt;p&gt;The book &#x27;RESTful Web Services&#x27; by Richardson and Ruby, while a bit dense, offers good insights on creating web-services (example: versioning). At some point, I&#x27;d like to come up with standards for Brown Library (and&#x2F;or campus-wide) web-services. Examples: specifying versioning in the url, a documention url in the returned data, and a url in that documentation of all APIs&#x2F;web-services the department offers.&lt;&#x2F;p&gt;
&lt;p&gt;For now, though, the simple shift toward moving code out of individual projects and onto the network has been rewarding.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
