<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title> - repositories</title>
    <link href="https://bspace.us/tags/repositories/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://bspace.us"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2023-08-21T00:00:00+00:00</updated>
    <id>https://bspace.us/tags/repositories/atom.xml</id>
    <entry xml:lang="en">
        <title>source of truth</title>
        <published>2023-08-21T00:00:00+00:00</published>
        <updated>2023-08-21T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/source-of-truth/" type="text/html"/>
        <id>https://bspace.us/posts/source-of-truth/</id>
        
        <content type="html">&lt;p&gt;Just read a great post from long-time &lt;a href=&quot;https:&#x2F;&#x2F;code4lib.org&#x2F;&quot; title=&quot;code4lib.org link&quot;&gt;code4libber&lt;&#x2F;a&gt; Jonathan Rochkind: &amp;quot;&lt;a href=&quot;https:&#x2F;&#x2F;bibwild.wordpress.com&#x2F;2023&#x2F;03&#x2F;21&#x2F;ocfl-and-source-of-truth-two-options&#x2F;&quot; title=&quot;source of truth link&quot;&gt;OCFL and ‘source of truth’ — two options&lt;&#x2F;a&gt;&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;To give a nutshell summary, it&#x27;s first useful to be aware of a common web-development pattern, where the &#x27;data&#x27; returned by a browser-request comes from an index. That index is an intermediary between the actual source data&#x2F;file, and the webpage a user loads.&lt;&#x2F;p&gt;
&lt;p&gt;An example... For two work-projects, the source-truth of the scholarly data is in xml-files (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Brown-University-Library&#x2F;usep-data&#x2F;tree&#x2F;master&#x2F;xml_inscriptions&#x2F;transcribed&quot; title=&quot;GitHub usep link&quot;&gt;example&lt;&#x2F;a&gt;). Knowedgeable trained folk encode data from headstones or other sources into these xml-files.&lt;&#x2F;p&gt;
&lt;p&gt;But when a user performs a search on the project&#x27;s webpage, or loads an inscription-page from the website, the server looks up info from our &lt;a href=&quot;https:&#x2F;&#x2F;solr.apache.org&#x2F;&quot; title=&quot;solr link&quot;&gt;solr&lt;&#x2F;a&gt; indexer.&lt;&#x2F;p&gt;
&lt;p&gt;Why the intermediary index? Partly because indexers are very, very fast. Also because they can deliver great search results in a way that offers a user easy and useful ways to filter results (&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Faceted_search&quot; title=&quot;facet wikipedia link&quot;&gt;&amp;quot;facets&amp;quot;&lt;&#x2F;a&gt;). And also because the most common indexers are very easy for developers to configure and query and update.&lt;&#x2F;p&gt;
&lt;p&gt;Given this small architectural tour, since the data for a web-request comes most directly from the index (not the xml files), it&#x27;s easy to see how the &amp;quot;source-of-truth&amp;quot; &lt;em&gt;could&lt;&#x2F;em&gt; be thought of as the index. If an xml-file hasn&#x27;t been indexed, it won&#x27;t appear on the website; in a way, it doesn&#x27;t exist.&lt;&#x2F;p&gt;
&lt;p&gt;Jonathan&#x27;s post focuses on a specification for saving files-and-associated-metadata to a filesystem, called &lt;a href=&quot;https:&#x2F;&#x2F;ocfl.io&#x2F;&quot; title=&quot;OCFL link&quot;&gt;OCFL&lt;&#x2F;a&gt; (&amp;quot;Oxford Common File Layout&amp;quot;). Though the uses of OCFL are not limited to repositories, it was developed from University repository-developers deliberating about, and implementing, a simple useful file-layout specification that different software-tools can use. &lt;&#x2F;p&gt;
&lt;p&gt;Because OCFL is most common in this repository context, and because repositories conceptually prioritize archival durability, OCFL data tends to be thought of as &amp;quot;source of truth&amp;quot; data in repository-architecture. &lt;&#x2F;p&gt;
&lt;p&gt;But repositories use indexers. Jonathan&#x27;s post illuminates competing visions of whether the OCFL storage-layer, or the indexer (or some correlative intermediary) should be considered the &amp;quot;source of truth&amp;quot; -- and the implications for decisions. My take is a bit different than his about the increased technical challenges of an OCFL-first source-of-truth, vs an intermediary-first source-of-truth -- but the main take-away for me is that it&#x27;s important to be very clear on what the purposes are for the two layers.&lt;&#x2F;p&gt;
&lt;p&gt;For the &lt;a href=&quot;https:&#x2F;&#x2F;repository.library.brown.edu&#x2F;studio&#x2F;&quot; title=&quot;BDR link&quot;&gt;BDR&lt;&#x2F;a&gt; (Brown Digital Repository), we want to ensure that if some disaster struck, and all the the BDR&#x27;s infrastructure went down, but we still had the offsite-OCFL-file-data (and our indexer-code in GitHub), we could reconstitute the BDR.&lt;&#x2F;p&gt;
&lt;p&gt;But other projects may lend themselves to a &lt;em&gt;shared&lt;&#x2F;em&gt; source-of-truth between the two key layers. &lt;&#x2F;p&gt;
&lt;p&gt;For a current work project, the main data-source is a FileMaker-Pro database. That data is exported, and indexed; the website accesses the index. A long-term project is underway to scan this collection&#x27;s materials, and put them in the BDR. Once there, we&#x27;ll naturally want to link to the relevant BDR-content from the website. How to do that?&lt;&#x2F;p&gt;
&lt;p&gt;For various reasons, we&#x27;ve decided not to add BDR links to the FileMaker-Pro database. Instead, we&#x27;ll add those urls directly to the index. So there will be very useful data in the index that&#x27;s not in the foundational source-data.&lt;&#x2F;p&gt;
&lt;p&gt;But that&#x27;s ok -- the important thing is to be clear and deliberate about what data is going where, for what reasons. And to be clear about how a useful website can be reconstituted from that source-data if needed. These are issues that we developers are &lt;em&gt;familiar&lt;&#x2F;em&gt; with, but given time and resource constraints, may not always think through deeply and document clearly. Which is why I so appreciate Jonathan&#x27;s post: it raises a variety of useful issues to work through intentionally.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>opportunites of benign-neglect</title>
        <published>2010-02-24T00:00:00+00:00</published>
        <updated>2010-02-24T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/benign-neglect-opportunities/" type="text/html"/>
        <id>https://bspace.us/posts/benign-neglect-opportunities/</id>
        
        <content type="html">&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cathy_Marshall_(hypertext_developer)&quot;&gt;Cathy Marshall&lt;&#x2F;a&gt; of Microsoft Research gave a keynote at the wonderful &lt;a href=&quot;http:&#x2F;&#x2F;code4lib.org&#x2F;conference&#x2F;2010&#x2F;&quot;&gt;code4lib 2010 conference&lt;&#x2F;a&gt; that provided a useful nudge to my thinking about repository layers.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve suggested &lt;a href=&quot;https:&#x2F;&#x2F;bspace.us&#x2F;posts&#x2F;the-wave-and-repository&#x2F;&quot;&gt;elsewhere&lt;&#x2F;a&gt; that university libraries contemplating a repository should consider developing policies around repository &#x27;layers&#x27;. This notion involves both an inner long-term, high-guarantee archival layer -- and an outer services-oriented work-space layer. Reasons for the archival layer are obvious. Perhaps less so are reasons for and benefits of the work-space layer: it fulfills a library mission to further scholarly work; it strengthens the library&#x27;s position as a central part of the academic campus community; it creates opportunities for valuable work to be moved easily into the archival layer.&lt;&#x2F;p&gt;
&lt;p&gt;Though my Library doesn&#x27;t conceptualize our repository in this way, it&#x27;s compelling enough that I think about this layered approach regularly. Given some exciting video initiatives at my University, much of my recent work-space layer thinking has focused on how to avoid the possibility of having precious library disk space overwhelmed with hypothetical services-layer low(er) quality materials. Strategies I&#x27;ve considered to deal with this concern are combinations of limiting the size of an entity&#x27;s (person&#x2F;department) work-space, and&#x2F;or limiting the number of years items may remain in the work-space. Given my strong belief in providing useful and friendly user-services, in this &#x27;limiting&#x27; scenario, we would provide terrific charts and notifications which would allow work-space users to easily monitor their usage of this temporal, useful space -- and provide tools and Library staff assistance to easily move appropriate items into the archival layer.&lt;&#x2F;p&gt;
&lt;p&gt;But regardless of the intention to have this work-space be used productively, there would be a high likelihood that the more control we give users over their Library work-space, the more likely that a significant portion of this work-space would fill up with materials that exist simply because it&#x27;s more of a hassle to delete things than it is to neglect them -- one of Marshall&#x27;s key points.&lt;&#x2F;p&gt;
&lt;p&gt;While Marshall specifically noted the problems of benign-neglect as a user-strategy for handling materials, she also noted that benign neglect offers opportunities. This was the nudge. I&#x27;m finding this notion of opportunities fascinating to reflect upon; it offers new realms for thinking about interesting services that could be built for this work-space layer.&lt;&#x2F;p&gt;
&lt;p&gt;The simple accretion of data from benign neglect suggests the now-common mining strategy associated with usage-data, popularized by amazon: &amp;quot;you may also be interested in this&amp;quot;. A colleague recently told me about &#x27;&lt;a href=&quot;http:&#x2F;&#x2F;tinyurl.com&#x2F;y8oowqa&quot;&gt;mallet&lt;&#x2F;a&gt;&#x27;, software than can mine texts to discern topics. It would be a worthy experiment to use such a tool to offer repository users an optional discovery service based on their text-based work-space materials.&lt;&#x2F;p&gt;
&lt;p&gt;Two additions to Apple&#x27;s iPhoto application in the last year or so suggest other possibilities. &#x27;Faces&#x27; scans a user&#x27;s iPhoto library, using pattern-recognition routines to create groupings of people. &#x27;Places&#x27; scan&#x27;s the library and extracts geo-location coordinates if available, and, if I recall correctly, timestamp data, to create a map view over time of photo-locations.&lt;&#x2F;p&gt;
&lt;p&gt;Other scans could be run on work-space data, looking for patterns of government data-sets or citations. And &lt;em&gt;combinations&lt;&#x2F;em&gt; of embedded metadata such as geo-location and mime-type and date could be gathered, so that if, for example, a pattern of images taken at a certain location on a certain date was detected, not only could auto-grouping of those items be presented, but external sources such as flickr could be queried as well, offering the user the ability to see other external views of this &#x27;event&#x27;.&lt;&#x2F;p&gt;
&lt;p&gt;Many of these scan&#x2F;mining ideas would also be useful to apply to the repository as a whole. Such scans could offer both automated randomized general-discovery displays, as well as offer researchers additional focused discovery-views to permitted items. But to the extent that such services enhance the quality of users&#x27; work-space experience, it might help to keep the materials in the work-space more relevant: using benign-neglect to minimize benign-neglect.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>shibboleth and fedora</title>
        <published>2010-01-16T00:00:00+00:00</published>
        <updated>2010-01-16T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/shib-and-fedora/" type="text/html"/>
        <id>https://bspace.us/posts/shib-and-fedora/</id>
        
        <content type="html">&lt;p&gt;&lt;em&gt;[2023 update -- our repository architecture has changed significantly (I&#x27;ll post about it sometime), so this post (like so many old tech-posts) is for posterity. 🙂 ]&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;I don&#x27;t work directly on &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fedora_(software)&quot;&gt;Fedora&lt;&#x2F;a&gt; (our repository software), but am very familiar with it due to my work with a programmer who does, and because I&#x27;ve worked on a &lt;a href=&quot;http:&#x2F;&#x2F;www.djangoproject.com&#x2F;&quot;&gt;django&lt;&#x2F;a&gt; front-end for ingestion of items into fedora, as well as fedora-apis. My role in fedora work is more akin to the &#x27;corner-man&#x27; in boxing. Together the boxer and I strategize about the opponent, his defenses and threats to our plans, and devise approaches to deal with evolving challenges. We cross ourselves, the fedora programmer goes into the ring, and between rounds I provide moral support, bandage wounds, and, because of my distance from actual battle, sometimes have useful ideas for the next round. This analogy&#x27;s negativity toward the Fedora software is appropriate; to use another: We&#x27;ve bought a car that, in hindsight, I wouldn&#x27;t recommend to others, but that we&#x27;re committed to getting some terrific mileage out of.&lt;&#x2F;p&gt;
&lt;p&gt;So, it&#x27;s been a tough fight, but our boxer is quick, has impressive endurance, and we believe we&#x27;ll come out on top.&lt;&#x2F;p&gt;
&lt;p&gt;Fedora authorization is one round in which we think we&#x27;ve scored well.&lt;&#x2F;p&gt;
&lt;p&gt;Fedora comes bundled with an authorization piece called &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;XACML&quot;&gt;XACML&lt;&#x2F;a&gt;. I don&#x27;t know if it&#x27;s due to xacml, or fedora&#x27;s implementation of it, but from what I gather indirectly, it&#x27;s terrifying enough that few use it, and it is, in fact, scheduled to be augmented in a future release with a new Great Hope: &lt;a href=&quot;https:&#x2F;&#x2F;wiki.lyrasis.org&#x2F;display&#x2F;FEDORA34&#x2F;FeSL+Authentication&quot;&gt;FeSL&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;But if you want to go into production &lt;em&gt;now&lt;&#x2F;em&gt;, what to do? The dearth of published authentication&#x2F;authorization &#x27;live&#x27; solutions is why, as I understand it, so many fedora installations are either completely open (all objects public), or completely locked down for internal use.&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;ve assumed we would use some sort of wrapper around fedora, to authenticate against &lt;a href=&quot;http:&#x2F;&#x2F;shibboleth.internet2.edu&#x2F;&quot;&gt;Shibboleth&lt;&#x2F;a&gt;, with which our university is slowly moving forward. Shib&#x27;s lack of logout capability, and the resultant assumption that users will happily quit their browser to logout, would seem quaintly amusing if it weren&#x27;t true -- but that is another topic entirely, and single sign-on is certainly convenient. Not long ago we began to tackle how, specifically, to implement shib&#x2F;fedora authorization.&lt;&#x2F;p&gt;
&lt;p&gt;Recently someone described to me an authorization approach the &lt;a href=&quot;http:&#x2F;&#x2F;www.muradora.org&#x2F;muradora&quot;&gt;muradora&lt;&#x2F;a&gt; folk took. I haven&#x27;t looked at any documentation myself, but I was told that they wrote a servlet filter that takes a submitted name and password, and passes it to a non-centralized custom ldap server that exists only for the purpose of allowing fedora&#x27;s built in ldap-xacml code to handle authentication. (For those unfamiliar: a java servlet filter acts as a front layer of a java webapp through which incoming requests and outgoing responses must pass, and can be modified.) &lt;&#x2F;p&gt;
&lt;p&gt;A few of us heard this and had divergent reactions. It sounded like a hack, which caused some to dismiss the approach. Personally, being quite partial to hacks that work around monolithic software obstacles, I thought the hack smacked of ingenious creativity and was worth further examination. I was indulged; the result: our corner has devised an approach that initial testing indicates will work well.&lt;&#x2F;p&gt;
&lt;p&gt;First, some necessary background info... &lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Our University shib implementation is integrated with &lt;a href=&quot;http:&#x2F;&#x2F;www.internet2.edu&#x2F;grouper&#x2F;&quot;&gt;Grouper&lt;&#x2F;a&gt;. I think grouper is, or at least historically has been, a separate project from shibboleth, but they work together brilliantly. Upon shib-login, a list of the groups to which the user belongs is accessible to the server via the shib &#x27;is-member-of&#x27; header field.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Our implementation of fedora item ingestion involves creating a &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;METS&quot;&gt;METS&lt;&#x2F;a&gt; record that contains a bunch of item-info -- including a rights segment. The rights segment contains a series of entries, each one listing an identity (a shib is-member-of group) and a permission. Example (content, not format): identity=&#x27;chemistry-department&#x27; &amp;amp; permission=&#x27;view_item&#x27;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The mets record is handed to an ingester that converts the mets xml to &lt;a href=&quot;http:&#x2F;&#x2F;www.fedora-commons.org&#x2F;download&#x2F;2.0&#x2F;userdocs&#x2F;digitalobjects&#x2F;introFOXML.html&quot;&gt;FOXML&lt;&#x2F;a&gt;, then fedora grabs the object (we&#x27;re using the &#x27;managed&#x27; option at the moment), and the java messaging built into fedora fires off a message to a listener that indexes (via &lt;a href=&quot;http:&#x2F;&#x2F;lucene.apache.org&#x2F;solr&#x2F;&quot;&gt;Solr&lt;&#x2F;a&gt;) parts of the foxml record, including the rights information.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;So, our approach: create a fedora servlet filter that reads the shib groups&#x2F;identities, then does a solr search to see if the object being requested has a &#x27;view&#x27; permission for any of the identities in the request&#x27;s shib is-member-of header. If so, the request is allowed through; if not; it is blocked. If no shib-identity is found, the servlet filter will only yield objects with &#x27;public&#x27; view_item permissions. &lt;&#x2F;p&gt;
&lt;p&gt;The beauty of this is that fedora-access can be fully open to the internet while still allowing authorized access for those objects that require it. Further, this solution offers reasonable hope that it will survive fedora upgrades, since the servlet, though a part of the fedora webapp, is somewhat of a separate layer in front of the app. Further, by adding more granular permissions (at the moment permissions are at the object-level; they could be at the data-stream level) -- or simply by a bit of extra programming in the servlet-filter -- we could allow, say, the public to access low and medium-resolution images, but allow, say, faculty to access high-resolution images.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I&#x27;ll keep this paragraph updated...&lt;&#x2F;em&gt; Our intrepid programmer has figured out where to insert the custom servlet filter, has worked with our systems person to hook up an initial apache&#x2F;tomcat connection so as to allow the shib installation on apache to pass its headers through to tomcat, and confirmed the filter&#x27;s detection of the shib identity header information. A nice side-effect of installing shib on apache rather than tomcat directly is that we can allow programmatic access to port 8080.&lt;&#x2F;p&gt;
&lt;p&gt;The bell has rung; the next round begins. We cross our fingers, and the programmer heads into the ring once again.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>the wave and the repository</title>
        <published>2009-11-11T00:00:00+00:00</published>
        <updated>2009-11-11T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/the-wave-and-repository/" type="text/html"/>
        <id>https://bspace.us/posts/the-wave-and-repository/</id>
        
        <content type="html">&lt;p&gt;I&#x27;ve been playing with &lt;a href=&quot;http:&#x2F;&#x2F;wave.google.com&quot;&gt;Google Wave&lt;&#x2F;a&gt; recently and am deeply impressed.&lt;&#x2F;p&gt;
&lt;p&gt;I would not be surprised if within a few years, a year for many, waves will largely replace emails. Not just for youth, whose primary forms of non-voice digital communication are sms-texts or facebook-posts, but also for those of us for whom email is currently an absolutely essential daily form of communication.&lt;&#x2F;p&gt;
&lt;p&gt;I believe it will be that significant.&lt;&#x2F;p&gt;
&lt;p&gt;For those not familiar with Google Wave, here are some links:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Google_Wave&quot;&gt;wikipedia entry&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Since you really have to see it in action, &lt;a href=&quot;http:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Itc4253kjhw&quot;&gt;here&lt;&#x2F;a&gt; is an abridged version of the &lt;a href=&quot;http:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=v_UyVmITiYQ&amp;amp;feature=player_embedded&quot;&gt;1hr20min introduction&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;The &lt;a href=&quot;http:&#x2F;&#x2F;wave.google.com&#x2F;&quot;&gt;main site&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;My mind-wheels have been spinning, envisioning what this new form of communication could impact.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;library-digital-repository&quot;&gt;Library digital repository&lt;&#x2F;h2&gt;
&lt;p&gt;At the &lt;a href=&quot;http:&#x2F;&#x2F;access2007.uvic.ca&#x2F;?page_id=18&quot;&gt;Access 2007&lt;&#x2F;a&gt; conference I saw an &lt;a href=&quot;http:&#x2F;&#x2F;video.google.ca&#x2F;videoplay?docid=6976320823933843470&amp;amp;hl=en-CA#&quot;&gt;inspiring talk&lt;&#x2F;a&gt; by Mark Leggott of the &lt;a href=&quot;http:&#x2F;&#x2F;library.upei.ca&#x2F;&quot;&gt;University of Prince Edward Island&lt;&#x2F;a&gt;. He spoke about the &lt;a href=&quot;http:&#x2F;&#x2F;vre2.upei.ca&#x2F;access2009&#x2F;vre&quot;&gt;Virtual Research Environment&lt;&#x2F;a&gt; that his group had created, which successfully addressed a thorny issue: Libraries which had  expended significant resources to build digital repository systems were having a terrible time getting campus entities to contribute content.&lt;&#x2F;p&gt;
&lt;p&gt;What was so compelling about Leggott&#x27;s approach was his team&#x27;s shift in perspective from expecting users to meet Library requirements -- to the Library meeting users&#x27; needs. I was still fairly new to the Library world at that time, but my sense was that institutions had built their digital repository to meet Library needs for thorough meta-data -- without much regard to user-experience or needs. The result: the new digital repository felt irrelevant to campus users. With onerous submission processes and requirements, little material was submitted. Leggott&#x27;s team instead focused directly on useful services to key campus constituents such as faculty -- allowing them to more easily do the work they already did. As I recall, one simple example was that his group provided storage space for research data-sets -- but I believe the offer wasn&#x27;t just for &lt;em&gt;final&lt;&#x2F;em&gt; data-sets, but data-sets under active development, revision, and analysis. The result: campus digital work worthy of inclusion into the repository was &lt;em&gt;already within&lt;&#x2F;em&gt; the UPEI Library system, which made final repository ingestion of appropriate material architecturally easy.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;layering&quot;&gt;Layering&lt;&#x2F;h2&gt;
&lt;p&gt;Now that I have one work-foot in the digital repository world, I&#x27;ve been wondering about an issue stemming from my recollection of the Leggott team&#x27;s approach: how to design a compelling suite of storage and easy-to-use services, without the Library repository being filled with vacation and pet pictures?&lt;&#x2F;p&gt;
&lt;p&gt;My thought: the Library could develop clear, simple policies for &lt;em&gt;layers&lt;&#x2F;em&gt; of repository-usage. The outer layer would be more flexible, more transactional, and would require a lower-level of quality metadata for submitted items -- tags would be fine. We already have a mission to support transactional, often non-archival work: supporting research. For items to be accepted into the inner more archival layer, more and higher quality metadata would be required, in exchange for the guarantee of permanence, multiple-channel data exposure, and format data-migration. The benefits of this layered approach: the Library can play an increased central role in the creative work of the campus, and ensure access to  quality data from across campus that would flow into the repository.&lt;&#x2F;p&gt;
&lt;p&gt;From this layering idea arises the question of how to architecturally separate the layers. Brainstorming, I&#x27;ve imagined that campus users could be allotted x00 GB of outer-layer &#x27;work&#x27; storage-space -- with more inner-layer repository-space just a click away for items deemed appropriate. Or the outer-layer work space could be limited by time-frame: all files in the outer-layer workspace could have, say, a two-year lifespan, with a nice status-report system so no one would lose work unexpectedly. That&#x27;d help encourage worthy materials to be migrated into the inner layer.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;leveraging&quot;&gt;Leveraging&lt;&#x2F;h2&gt;
&lt;p&gt;Recently, my thinking is shifting in a different direction. I still like the idea of an outer transactional work-layer, and an inner repository layer with richer metadata and higher archival guarantees. But I question whether we need to build all the outer-layer services. An alternate approach would be to facilitate the use of existing third-party services and tools, and build Library services, plugins, and widgets to streamline the ingestion of appropriate items from those external third-party work-layer services and tools.&lt;&#x2F;p&gt;
&lt;p&gt;My recent experimentation with Google Wave was a catalyst for this shift, especially given its collaborative strengths, and its ability to easily handle files and images via drag &amp;amp; drop.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;vision&quot;&gt;Vision&lt;&#x2F;h2&gt;
&lt;p&gt;One of the use-cases we&#x27;ve envisioned for use of our digital repository is a professor organizing images for a class presentation. Imagine the professor is working with teaching assistants (TAs) to refine the presentation and associated points. With Google Wave, the professor could set up a wave to prepare for the class session. She could invite her two TAs into the wave; each could simply drag pictures into the wave, tagging them. The professor could also set up a bullet-point list in the wave, encourage the TAs to contribute to the bullet-list, and note issues for them to research in preparation for the class session.&lt;&#x2F;p&gt;
&lt;p&gt;Imagine if, when the session-material preparation is complete, the professor could then apply a Library repository-gadget to the wave which would, after a campus authentication process, ingest all the pictures and associated titles (and, optionally, the wave itself), and redirect the prof to a repository web-page to enter a bit more metadata. Upon adding this extra information, the data would be officially ingested into the repository. Because Google Wave is an open-source project, the Library or campus IT folk could, if desired, install a wave server to facilitate branding and make it all the easier for Libary services to be integrated seamlessly into users&#x27; work flow.&lt;&#x2F;p&gt;
&lt;p&gt;Google wave comes with an &lt;a href=&quot;https:&#x2F;&#x2F;wave.google.com&#x2F;help&#x2F;wave&#x2F;extensions.html&quot;&gt;Extensions&lt;&#x2F;a&gt; Gallery that provides inspiration for imagining the varied kinds of services that can be applied to a wave, and tutorials abound on &lt;a href=&quot;http:&#x2F;&#x2F;googlewavedev.blogspot.com&#x2F;2009&#x2F;05&#x2F;introducing-google-wave-apis-what-can.html&quot;&gt;how to program extensions&lt;&#x2F;a&gt;. The same approach could be applied to flickr and facebook: Library programmers could build widgets and mini-apps to enable users to use friendly tools and services they&#x27;re already comfortable with -- but to still be able to shift their works easily into the official repository. It&#x27;s part of the idea of meeting users where they are, as opposed to requiring that they come to us. That this approach offers new and exciting realms for Library programmers is just delicious gravy.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
