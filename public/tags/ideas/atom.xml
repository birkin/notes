<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title> - ideas</title>
    <link href="https://bspace.us/tags/ideas/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://bspace.us"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2010-02-24T00:00:00+00:00</updated>
    <id>https://bspace.us/tags/ideas/atom.xml</id>
    <entry xml:lang="en">
        <title>opportunites of benign-neglect</title>
        <published>2010-02-24T00:00:00+00:00</published>
        <updated>2010-02-24T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/benign-neglect-opportunities/" type="text/html"/>
        <id>https://bspace.us/posts/benign-neglect-opportunities/</id>
        
        <content type="html">&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cathy_Marshall_(hypertext_developer)&quot;&gt;Cathy Marshall&lt;&#x2F;a&gt; of Microsoft Research gave a keynote at the wonderful &lt;a href=&quot;http:&#x2F;&#x2F;code4lib.org&#x2F;conference&#x2F;2010&#x2F;&quot;&gt;code4lib 2010 conference&lt;&#x2F;a&gt; that provided a useful nudge to my thinking about repository layers.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve suggested &lt;a href=&quot;https:&#x2F;&#x2F;bspace.us&#x2F;posts&#x2F;the-wave-and-repository&#x2F;&quot;&gt;elsewhere&lt;&#x2F;a&gt; that university libraries contemplating a repository should consider developing policies around repository &#x27;layers&#x27;. This notion involves both an inner long-term, high-guarantee archival layer -- and an outer services-oriented work-space layer. Reasons for the archival layer are obvious. Perhaps less so are reasons for and benefits of the work-space layer: it fulfills a library mission to further scholarly work; it strengthens the library&#x27;s position as a central part of the academic campus community; it creates opportunities for valuable work to be moved easily into the archival layer.&lt;&#x2F;p&gt;
&lt;p&gt;Though my Library doesn&#x27;t conceptualize our repository in this way, it&#x27;s compelling enough that I think about this layered approach regularly. Given some exciting video initiatives at my University, much of my recent work-space layer thinking has focused on how to avoid the possibility of having precious library disk space overwhelmed with hypothetical services-layer low(er) quality materials. Strategies I&#x27;ve considered to deal with this concern are combinations of limiting the size of an entity&#x27;s (person&#x2F;department) work-space, and&#x2F;or limiting the number of years items may remain in the work-space. Given my strong belief in providing useful and friendly user-services, in this &#x27;limiting&#x27; scenario, we would provide terrific charts and notifications which would allow work-space users to easily monitor their usage of this temporal, useful space -- and provide tools and Library staff assistance to easily move appropriate items into the archival layer.&lt;&#x2F;p&gt;
&lt;p&gt;But regardless of the intention to have this work-space be used productively, there would be a high likelihood that the more control we give users over their Library work-space, the more likely that a significant portion of this work-space would fill up with materials that exist simply because it&#x27;s more of a hassle to delete things than it is to neglect them -- one of Marshall&#x27;s key points.&lt;&#x2F;p&gt;
&lt;p&gt;While Marshall specifically noted the problems of benign-neglect as a user-strategy for handling materials, she also noted that benign neglect offers opportunities. This was the nudge. I&#x27;m finding this notion of opportunities fascinating to reflect upon; it offers new realms for thinking about interesting services that could be built for this work-space layer.&lt;&#x2F;p&gt;
&lt;p&gt;The simple accretion of data from benign neglect suggests the now-common mining strategy associated with usage-data, popularized by amazon: &amp;quot;you may also be interested in this&amp;quot;. A colleague recently told me about &#x27;&lt;a href=&quot;http:&#x2F;&#x2F;tinyurl.com&#x2F;y8oowqa&quot;&gt;mallet&lt;&#x2F;a&gt;&#x27;, software than can mine texts to discern topics. It would be a worthy experiment to use such a tool to offer repository users an optional discovery service based on their text-based work-space materials.&lt;&#x2F;p&gt;
&lt;p&gt;Two additions to Apple&#x27;s iPhoto application in the last year or so suggest other possibilities. &#x27;Faces&#x27; scans a user&#x27;s iPhoto library, using pattern-recognition routines to create groupings of people. &#x27;Places&#x27; scan&#x27;s the library and extracts geo-location coordinates if available, and, if I recall correctly, timestamp data, to create a map view over time of photo-locations.&lt;&#x2F;p&gt;
&lt;p&gt;Other scans could be run on work-space data, looking for patterns of government data-sets or citations. And &lt;em&gt;combinations&lt;&#x2F;em&gt; of embedded metadata such as geo-location and mime-type and date could be gathered, so that if, for example, a pattern of images taken at a certain location on a certain date was detected, not only could auto-grouping of those items be presented, but external sources such as flickr could be queried as well, offering the user the ability to see other external views of this &#x27;event&#x27;.&lt;&#x2F;p&gt;
&lt;p&gt;Many of these scan&#x2F;mining ideas would also be useful to apply to the repository as a whole. Such scans could offer both automated randomized general-discovery displays, as well as offer researchers additional focused discovery-views to permitted items. But to the extent that such services enhance the quality of users&#x27; work-space experience, it might help to keep the materials in the work-space more relevant: using benign-neglect to minimize benign-neglect.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>shibboleth and fedora</title>
        <published>2010-01-16T00:00:00+00:00</published>
        <updated>2010-01-16T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/shib-and-fedora/" type="text/html"/>
        <id>https://bspace.us/posts/shib-and-fedora/</id>
        
        <content type="html">&lt;p&gt;&lt;em&gt;[2023 update -- our repository architecture has changed significantly (I&#x27;ll post about it sometime), so this post (like so many old tech-posts) is for posterity. ðŸ™‚ ]&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;I don&#x27;t work directly on &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fedora_(software)&quot;&gt;Fedora&lt;&#x2F;a&gt; (our repository software), but am very familiar with it due to my work with a programmer who does, and because I&#x27;ve worked on a &lt;a href=&quot;http:&#x2F;&#x2F;www.djangoproject.com&#x2F;&quot;&gt;django&lt;&#x2F;a&gt; front-end for ingestion of items into fedora, as well as fedora-apis. My role in fedora work is more akin to the &#x27;corner-man&#x27; in boxing. Together the boxer and I strategize about the opponent, his defenses and threats to our plans, and devise approaches to deal with evolving challenges. We cross ourselves, the fedora programmer goes into the ring, and between rounds I provide moral support, bandage wounds, and, because of my distance from actual battle, sometimes have useful ideas for the next round. This analogy&#x27;s negativity toward the Fedora software is appropriate; to use another: We&#x27;ve bought a car that, in hindsight, I wouldn&#x27;t recommend to others, but that we&#x27;re committed to getting some terrific mileage out of.&lt;&#x2F;p&gt;
&lt;p&gt;So, it&#x27;s been a tough fight, but our boxer is quick, has impressive endurance, and we believe we&#x27;ll come out on top.&lt;&#x2F;p&gt;
&lt;p&gt;Fedora authorization is one round in which we think we&#x27;ve scored well.&lt;&#x2F;p&gt;
&lt;p&gt;Fedora comes bundled with an authorization piece called &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;XACML&quot;&gt;XACML&lt;&#x2F;a&gt;. I don&#x27;t know if it&#x27;s due to xacml, or fedora&#x27;s implementation of it, but from what I gather indirectly, it&#x27;s terrifying enough that few use it, and it is, in fact, scheduled to be augmented in a future release with a new Great Hope: &lt;a href=&quot;https:&#x2F;&#x2F;wiki.lyrasis.org&#x2F;display&#x2F;FEDORA34&#x2F;FeSL+Authentication&quot;&gt;FeSL&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;But if you want to go into production &lt;em&gt;now&lt;&#x2F;em&gt;, what to do? The dearth of published authentication&#x2F;authorization &#x27;live&#x27; solutions is why, as I understand it, so many fedora installations are either completely open (all objects public), or completely locked down for internal use.&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;ve assumed we would use some sort of wrapper around fedora, to authenticate against &lt;a href=&quot;http:&#x2F;&#x2F;shibboleth.internet2.edu&#x2F;&quot;&gt;Shibboleth&lt;&#x2F;a&gt;, with which our university is slowly moving forward. Shib&#x27;s lack of logout capability, and the resultant assumption that users will happily quit their browser to logout, would seem quaintly amusing if it weren&#x27;t true -- but that is another topic entirely, and single sign-on is certainly convenient. Not long ago we began to tackle how, specifically, to implement shib&#x2F;fedora authorization.&lt;&#x2F;p&gt;
&lt;p&gt;Recently someone described to me an authorization approach the &lt;a href=&quot;http:&#x2F;&#x2F;www.muradora.org&#x2F;muradora&quot;&gt;muradora&lt;&#x2F;a&gt; folk took. I haven&#x27;t looked at any documentation myself, but I was told that they wrote a servlet filter that takes a submitted name and password, and passes it to a non-centralized custom ldap server that exists only for the purpose of allowing fedora&#x27;s built in ldap-xacml code to handle authentication. (For those unfamiliar: a java servlet filter acts as a front layer of a java webapp through which incoming requests and outgoing responses must pass, and can be modified.) &lt;&#x2F;p&gt;
&lt;p&gt;A few of us heard this and had divergent reactions. It sounded like a hack, which caused some to dismiss the approach. Personally, being quite partial to hacks that work around monolithic software obstacles, I thought the hack smacked of ingenious creativity and was worth further examination. I was indulged; the result: our corner has devised an approach that initial testing indicates will work well.&lt;&#x2F;p&gt;
&lt;p&gt;First, some necessary background info... &lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Our University shib implementation is integrated with &lt;a href=&quot;http:&#x2F;&#x2F;www.internet2.edu&#x2F;grouper&#x2F;&quot;&gt;Grouper&lt;&#x2F;a&gt;. I think grouper is, or at least historically has been, a separate project from shibboleth, but they work together brilliantly. Upon shib-login, a list of the groups to which the user belongs is accessible to the server via the shib &#x27;is-member-of&#x27; header field.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Our implementation of fedora item ingestion involves creating a &lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;METS&quot;&gt;METS&lt;&#x2F;a&gt; record that contains a bunch of item-info -- including a rights segment. The rights segment contains a series of entries, each one listing an identity (a shib is-member-of group) and a permission. Example (content, not format): identity=&#x27;chemistry-department&#x27; &amp;amp; permission=&#x27;view_item&#x27;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The mets record is handed to an ingester that converts the mets xml to &lt;a href=&quot;http:&#x2F;&#x2F;www.fedora-commons.org&#x2F;download&#x2F;2.0&#x2F;userdocs&#x2F;digitalobjects&#x2F;introFOXML.html&quot;&gt;FOXML&lt;&#x2F;a&gt;, then fedora grabs the object (we&#x27;re using the &#x27;managed&#x27; option at the moment), and the java messaging built into fedora fires off a message to a listener that indexes (via &lt;a href=&quot;http:&#x2F;&#x2F;lucene.apache.org&#x2F;solr&#x2F;&quot;&gt;Solr&lt;&#x2F;a&gt;) parts of the foxml record, including the rights information.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;So, our approach: create a fedora servlet filter that reads the shib groups&#x2F;identities, then does a solr search to see if the object being requested has a &#x27;view&#x27; permission for any of the identities in the request&#x27;s shib is-member-of header. If so, the request is allowed through; if not; it is blocked. If no shib-identity is found, the servlet filter will only yield objects with &#x27;public&#x27; view_item permissions. &lt;&#x2F;p&gt;
&lt;p&gt;The beauty of this is that fedora-access can be fully open to the internet while still allowing authorized access for those objects that require it. Further, this solution offers reasonable hope that it will survive fedora upgrades, since the servlet, though a part of the fedora webapp, is somewhat of a separate layer in front of the app. Further, by adding more granular permissions (at the moment permissions are at the object-level; they could be at the data-stream level) -- or simply by a bit of extra programming in the servlet-filter -- we could allow, say, the public to access low and medium-resolution images, but allow, say, faculty to access high-resolution images.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I&#x27;ll keep this paragraph updated...&lt;&#x2F;em&gt; Our intrepid programmer has figured out where to insert the custom servlet filter, has worked with our systems person to hook up an initial apache&#x2F;tomcat connection so as to allow the shib installation on apache to pass its headers through to tomcat, and confirmed the filter&#x27;s detection of the shib identity header information. A nice side-effect of installing shib on apache rather than tomcat directly is that we can allow programmatic access to port 8080.&lt;&#x2F;p&gt;
&lt;p&gt;The bell has rung; the next round begins. We cross our fingers, and the programmer heads into the ring once again.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>the wave and the repository</title>
        <published>2009-11-11T00:00:00+00:00</published>
        <updated>2009-11-11T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/the-wave-and-repository/" type="text/html"/>
        <id>https://bspace.us/posts/the-wave-and-repository/</id>
        
        <content type="html">&lt;p&gt;I&#x27;ve been playing with &lt;a href=&quot;http:&#x2F;&#x2F;wave.google.com&quot;&gt;Google Wave&lt;&#x2F;a&gt; recently and am deeply impressed.&lt;&#x2F;p&gt;
&lt;p&gt;I would not be surprised if within a few years, a year for many, waves will largely replace emails. Not just for youth, whose primary forms of non-voice digital communication are sms-texts or facebook-posts, but also for those of us for whom email is currently an absolutely essential daily form of communication.&lt;&#x2F;p&gt;
&lt;p&gt;I believe it will be that significant.&lt;&#x2F;p&gt;
&lt;p&gt;For those not familiar with Google Wave, here are some links:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Google_Wave&quot;&gt;wikipedia entry&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Since you really have to see it in action, &lt;a href=&quot;http:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Itc4253kjhw&quot;&gt;here&lt;&#x2F;a&gt; is an abridged version of the &lt;a href=&quot;http:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=v_UyVmITiYQ&amp;amp;feature=player_embedded&quot;&gt;1hr20min introduction&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;The &lt;a href=&quot;http:&#x2F;&#x2F;wave.google.com&#x2F;&quot;&gt;main site&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;My mind-wheels have been spinning, envisioning what this new form of communication could impact.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;library-digital-repository&quot;&gt;Library digital repository&lt;&#x2F;h2&gt;
&lt;p&gt;At the &lt;a href=&quot;http:&#x2F;&#x2F;access2007.uvic.ca&#x2F;?page_id=18&quot;&gt;Access 2007&lt;&#x2F;a&gt; conference I saw an &lt;a href=&quot;http:&#x2F;&#x2F;video.google.ca&#x2F;videoplay?docid=6976320823933843470&amp;amp;hl=en-CA#&quot;&gt;inspiring talk&lt;&#x2F;a&gt; by Mark Leggott of the &lt;a href=&quot;http:&#x2F;&#x2F;library.upei.ca&#x2F;&quot;&gt;University of Prince Edward Island&lt;&#x2F;a&gt;. He spoke about the &lt;a href=&quot;http:&#x2F;&#x2F;vre2.upei.ca&#x2F;access2009&#x2F;vre&quot;&gt;Virtual Research Environment&lt;&#x2F;a&gt; that his group had created, which successfully addressed a thorny issue: Libraries which had  expended significant resources to build digital repository systems were having a terrible time getting campus entities to contribute content.&lt;&#x2F;p&gt;
&lt;p&gt;What was so compelling about Leggott&#x27;s approach was his team&#x27;s shift in perspective from expecting users to meet Library requirements -- to the Library meeting users&#x27; needs. I was still fairly new to the Library world at that time, but my sense was that institutions had built their digital repository to meet Library needs for thorough meta-data -- without much regard to user-experience or needs. The result: the new digital repository felt irrelevant to campus users. With onerous submission processes and requirements, little material was submitted. Leggott&#x27;s team instead focused directly on useful services to key campus constituents such as faculty -- allowing them to more easily do the work they already did. As I recall, one simple example was that his group provided storage space for research data-sets -- but I believe the offer wasn&#x27;t just for &lt;em&gt;final&lt;&#x2F;em&gt; data-sets, but data-sets under active development, revision, and analysis. The result: campus digital work worthy of inclusion into the repository was &lt;em&gt;already within&lt;&#x2F;em&gt; the UPEI Library system, which made final repository ingestion of appropriate material architecturally easy.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;layering&quot;&gt;Layering&lt;&#x2F;h2&gt;
&lt;p&gt;Now that I have one work-foot in the digital repository world, I&#x27;ve been wondering about an issue stemming from my recollection of the Leggott team&#x27;s approach: how to design a compelling suite of storage and easy-to-use services, without the Library repository being filled with vacation and pet pictures?&lt;&#x2F;p&gt;
&lt;p&gt;My thought: the Library could develop clear, simple policies for &lt;em&gt;layers&lt;&#x2F;em&gt; of repository-usage. The outer layer would be more flexible, more transactional, and would require a lower-level of quality metadata for submitted items -- tags would be fine. We already have a mission to support transactional, often non-archival work: supporting research. For items to be accepted into the inner more archival layer, more and higher quality metadata would be required, in exchange for the guarantee of permanence, multiple-channel data exposure, and format data-migration. The benefits of this layered approach: the Library can play an increased central role in the creative work of the campus, and ensure access to  quality data from across campus that would flow into the repository.&lt;&#x2F;p&gt;
&lt;p&gt;From this layering idea arises the question of how to architecturally separate the layers. Brainstorming, I&#x27;ve imagined that campus users could be allotted x00 GB of outer-layer &#x27;work&#x27; storage-space -- with more inner-layer repository-space just a click away for items deemed appropriate. Or the outer-layer work space could be limited by time-frame: all files in the outer-layer workspace could have, say, a two-year lifespan, with a nice status-report system so no one would lose work unexpectedly. That&#x27;d help encourage worthy materials to be migrated into the inner layer.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;leveraging&quot;&gt;Leveraging&lt;&#x2F;h2&gt;
&lt;p&gt;Recently, my thinking is shifting in a different direction. I still like the idea of an outer transactional work-layer, and an inner repository layer with richer metadata and higher archival guarantees. But I question whether we need to build all the outer-layer services. An alternate approach would be to facilitate the use of existing third-party services and tools, and build Library services, plugins, and widgets to streamline the ingestion of appropriate items from those external third-party work-layer services and tools.&lt;&#x2F;p&gt;
&lt;p&gt;My recent experimentation with Google Wave was a catalyst for this shift, especially given its collaborative strengths, and its ability to easily handle files and images via drag &amp;amp; drop.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;vision&quot;&gt;Vision&lt;&#x2F;h2&gt;
&lt;p&gt;One of the use-cases we&#x27;ve envisioned for use of our digital repository is a professor organizing images for a class presentation. Imagine the professor is working with teaching assistants (TAs) to refine the presentation and associated points. With Google Wave, the professor could set up a wave to prepare for the class session. She could invite her two TAs into the wave; each could simply drag pictures into the wave, tagging them. The professor could also set up a bullet-point list in the wave, encourage the TAs to contribute to the bullet-list, and note issues for them to research in preparation for the class session.&lt;&#x2F;p&gt;
&lt;p&gt;Imagine if, when the session-material preparation is complete, the professor could then apply a Library repository-gadget to the wave which would, after a campus authentication process, ingest all the pictures and associated titles (and, optionally, the wave itself), and redirect the prof to a repository web-page to enter a bit more metadata. Upon adding this extra information, the data would be officially ingested into the repository. Because Google Wave is an open-source project, the Library or campus IT folk could, if desired, install a wave server to facilitate branding and make it all the easier for Libary services to be integrated seamlessly into users&#x27; work flow.&lt;&#x2F;p&gt;
&lt;p&gt;Google wave comes with an &lt;a href=&quot;https:&#x2F;&#x2F;wave.google.com&#x2F;help&#x2F;wave&#x2F;extensions.html&quot;&gt;Extensions&lt;&#x2F;a&gt; Gallery that provides inspiration for imagining the varied kinds of services that can be applied to a wave, and tutorials abound on &lt;a href=&quot;http:&#x2F;&#x2F;googlewavedev.blogspot.com&#x2F;2009&#x2F;05&#x2F;introducing-google-wave-apis-what-can.html&quot;&gt;how to program extensions&lt;&#x2F;a&gt;. The same approach could be applied to flickr and facebook: Library programmers could build widgets and mini-apps to enable users to use friendly tools and services they&#x27;re already comfortable with -- but to still be able to shift their works easily into the official repository. It&#x27;s part of the idea of meeting users where they are, as opposed to requiring that they come to us. That this approach offers new and exciting realms for Library programmers is just delicious gravy.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>dashboard initiative</title>
        <published>2009-09-22T00:00:00+00:00</published>
        <updated>2009-09-22T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/dashboard-initiative/" type="text/html"/>
        <id>https://bspace.us/posts/dashboard-initiative/</id>
        
        <content type="html">&lt;p&gt;I&#x27;ve been putting some productive time into something I&#x27;m calling &amp;quot;The Dashboard Initiative&amp;quot;. Most of this time to date has been outside of normal work hours due to a few other priorities, but in time I expect to add this to the list of on-going work projects.&lt;&#x2F;p&gt;
&lt;p&gt;Inspired by work done by Brown&#x27;s &lt;a href=&quot;http:&#x2F;&#x2F;www.brown.edu&#x2F;Administration&#x2F;Institutional_Research&#x2F;&quot;&gt;Office of Institutional Research&lt;&#x2F;a&gt;, the concept of the dashboard is to provide useful trend information about the operation of different facets of the Library. The analogy to a car dashboard is good: whereas &#x27;instruments&#x27; make up a car&#x27;s dashboard, what I&#x27;m calling &#x27;widgets&#x27; make up the Library&#x27;s dashboard.&lt;&#x2F;p&gt;
&lt;p&gt;As shown on this &lt;a href=&quot;http:&#x2F;&#x2F;library.brown.edu&#x2F;dashboard&#x2F;info&#x2F;&quot;&gt;dashboard information page&lt;&#x2F;a&gt;, a dashboard widget consists of three counts (baseline, trend, and current), a trend indicator, and a &#x27;more-info&#x27; button that itself is a miniature graph. My visions for possible future dashboard usage within the Library and across campus are grand, but it is important to remember that the dashboard idea is intended to serve a rather specific data-display purpose: to usefully display trend information. Data that lends itself to pie-chart breakdowns can be important to an organization and can be an integral part of an organization&#x27;s data-farm, but is somewhat outside the scope of the dashboard focus on trends.&lt;&#x2F;p&gt;
&lt;p&gt;One of the reasons I find the dashboard concept so compelling is that it provides a kind of &#x27;template&#x27; for data-tracking feeds. Increasingly we&#x27;ve been building into more projects the ability to stream out statistic counts, but to date there hasn&#x27;t been a clear standardized vision of how this statistical data might be presented. The dashboard offers that standard.&lt;&#x2F;p&gt;
&lt;p&gt;If we were to rebuild from scratch the &lt;a href=&quot;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20210413162457&#x2F;https:&#x2F;&#x2F;library.brown.edu&#x2F;its&#x2F;software&#x2F;easyborrow&#x2F;&quot;&gt;easyBorrow&lt;&#x2F;a&gt; system, we could from the start automate count-flows that could populate widgets representing trend-usage for Josiah redirects, BorrowDirect, VirtualCatalog, InRhode, and Iliad. This of course applies to all new systems, and over time I expect we&#x27;ll retrofit many of our existing ad-hoc statistical counts to flow into widgets.&lt;&#x2F;p&gt;
&lt;p&gt;I have a vision of the creation, over time, of a plethora of widgets representing useful trend-information on checkouts, interlibrary-loan usage, new-titles additions, collections-web-access usage, requests for offsite materials, and physical library attendance to name just a few. This then begs the question of how to manage all these widgets.&lt;&#x2F;p&gt;
&lt;p&gt;I envision a &#x27;MyWidgets&#x27; page where, based on cookies and login, a user could view a listing of all Library widgets, filter by tag, and select those she finds useful for a personalized widget page. As part of my work I may pay particular attention to the flow of easyBorrow requests to our different borrowing partners, and scan other widgets tracking workbench file uploads to our in-development repository. Other folk in the library might be particularly interested in widgets that track numbers of books sent to our offsite Annex facility, as well as widgets that track the number of requests for those materials, and widgets that track how many requests for offsite materials are still made when the user is offered a link to a Google Book scan of the requested title. Our French scholarly resources librarian might choose for her page widgets tracking French new-title additions, as well as checkouts of French-language items.&lt;&#x2F;p&gt;
&lt;p&gt;Thinking even more broadly -- campus-wide -- it&#x27;s easy to imagine how, if other departments adopt the dashboard idea, a facility could even be developed for, say, the chair of the French department to &#x27;subscribe&#x27; to a Library &#x27;French New-Titles&#x27; widget, a Library &#x27;French-Language Checkouts&#x27; widget, as well as a Registrar widget representing the numbers of freshmen enrolled in French 1, and another Registrar widget representing numbers of French concentrators.&lt;&#x2F;p&gt;
&lt;p&gt;Along these lines, I expect to one-day add an rss and html parameter-segment to a widget-url to facilitate such cross-campus usage.&lt;&#x2F;p&gt;
&lt;p&gt;For now, starting on a small-scale, I&#x27;ve created via Django&#x27;s default admin a simple form allowing non-technical end-users to create a widget simply by typing or pasting into the form a list of key-value data-pairs.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;http:&#x2F;&#x2F;library.brown.edu&#x2F;django_media&#x2F;dashboard_media&#x2F;images&#x2F;form_sample.png&quot; alt=&quot;widget entry form&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Upon submitting the form, the data-points are parsed  and made into the discrete data-elements comprising a widget. This is in-place now. In fact, the widget on the &lt;a href=&quot;http:&#x2F;&#x2F;library.brown.edu&#x2F;dashboard&#x2F;info&#x2F;&quot;&gt;dashboard information page&lt;&#x2F;a&gt; was created (and can easily be updated) via this form. Further, this weekend I implemented the ability to view detail line-chart information using &lt;a href=&quot;http:&#x2F;&#x2F;code.google.com&#x2F;apis&#x2F;chart&#x2F;&quot;&gt;Google&#x27;s chart API&lt;&#x2F;a&gt;. So changing a label or data-point via the simple form now changes not just the widget but also the detail chart, on-the-fly. Though I expect to automate many data flows used to create dashboard widgets, the utility of the form will allow non-technical folk to take data they already create via manual processes and easily make that data much more visible to others.&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;ll see how this all unfolds. The potential is exciting.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;[ Update: I &lt;em&gt;&lt;a href=&quot;http:&#x2F;&#x2F;code4lib.org&#x2F;conference&#x2F;2009&#x2F;diana&quot;&gt;&lt;em&gt;presented&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;em&gt; on the dashboard at the &lt;em&gt;&lt;a href=&quot;http:&#x2F;&#x2F;code4lib.org&#x2F;conference&#x2F;2009&#x2F;schedule&quot;&gt;&lt;em&gt;2009 code4lib conference&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;em&gt;. Good feedback (&lt;&#x2F;em&gt;&lt;a href=&quot;http:&#x2F;&#x2F;twitter.com&#x2F;dchud&#x2F;statuses&#x2F;1245524571&quot;&gt;&lt;em&gt;DC&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;em&gt;, &lt;em&gt;&lt;a href=&quot;http:&#x2F;&#x2F;infomotions.com&#x2F;blog&#x2F;2009&#x2F;03&#x2F;code4lib-conference-providence-rhode-island-2009&#x2F;&quot;&gt;&lt;em&gt;ELM&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;em&gt;). ]&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>user-context</title>
        <published>2008-01-26T00:00:00+00:00</published>
        <updated>2008-01-26T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://bspace.us/posts/user-context/" type="text/html"/>
        <id>https://bspace.us/posts/user-context/</id>
        
        <content type="html">&lt;p&gt;I recently organized a meeting to brainstorm about what kinds of cool library things we could do if we knew more about a user&#x27;s context. I also put up a &lt;a href=&quot;http:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20100711222621&#x2F;https:&#x2F;&#x2F;wiki.brown.edu&#x2F;confluence&#x2F;display&#x2F;library&#x2F;User-context+brainstorming&quot;&gt;wiki-page&lt;&#x2F;a&gt; for the brainstorming process.&lt;&#x2F;p&gt;
&lt;p&gt;This stems from a requirement for a project: I had to be able to access a particular barcode related to a user. Turned out the only way of getting at this barcode was to first get another piece of information, and then use that first piece of information to call an API that returns a bunch of info about a user, including the barcode. Fine; did that; got the barcode and used it for a tunneler I built. I then went to the &lt;a href=&quot;http:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20130113222506&#x2F;http:&#x2F;&#x2F;access2007.uvic.ca&#x2F;?p=32&quot;&gt;Access 2007 conference&lt;&#x2F;a&gt;, a wonderful library programming&#x2F;technology conference, where, among other terrific presentations, I heard Mark Leggot speak[*] about the repository &lt;a href=&quot;http:&#x2F;&#x2F;loomware.typepad.com&#x2F;docs&#x2F;Repository_Redux_PubVersion.pdf&quot;&gt;presentation-PDF&lt;&#x2F;a&gt; he set up at the University of Prince Edward Island (UPEI). He mentioned the importance of understanding a user&#x27;s &#x27;context&#x27;. Something clicked, and the general implications of what our team had achieved by being able to tie a user&#x27;s log-in to this API-info about the user became clear.&lt;&#x2F;p&gt;
&lt;p&gt;This is nothing new in the internet business world; Amazon has been trailblazing this path for years. But given that authentication has mostly been a simple &#x27;boolean&#x27; system in our Library webapps of just determining whether or not a user is permitted to access a site -- this opens up worlds of exciting possibilities. Already we&#x27;ve implemented a proof-of-concept &#x27;drop box&#x27; that determines, from login, the user&#x27;s &#x27;type&#x27; (faculty&#x2F;staff&#x2F;student) and department and uses this data to customize the page displayed after login. Exciting stuff!&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Notes...&lt;&#x2F;p&gt;
&lt;p&gt;[*] The video of Mark Leggot&#x27;s presentation is no longer available; the reference was: &lt;code&gt;http:&#x2F;&#x2F;video.google.ca&#x2F;videoplay?docid=6976320823933843470&amp;amp;hl=en-CA&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
